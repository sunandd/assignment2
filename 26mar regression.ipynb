{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb6c076-80e3-485f-a33e-edf17ac0ae37",
   "metadata": {},
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\n",
    "example of each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54efd436-38dd-4fc5-8486-db6cd1d11345",
   "metadata": {},
   "source": [
    "Simple linear regression is a statistical method used to understand the relationship between two continuous variables (one predictor and one response variable). For example, if we want to predict rent based on square feet, that would be an example of simple linear regression.\n",
    "\n",
    "On the other hand, multiple linear regression is used when there are multiple predictor variables. For instance, if we want to predict rent based on square feet and age of the building, that would be an example of multiple linear regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64ca41b-3e6a-4ec3-a503-4d71a12d9bc8",
   "metadata": {},
   "source": [
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb5b585-f589-4fee-a4c6-e6697b5f77ac",
   "metadata": {},
   "source": [
    "Linear regression has several key assumptions that must be met before conducting the analysis. These include:\n",
    "\n",
    "1-Linear relationship: There exists a linear relationship between the independent variable(s) and the dependent variable.\n",
    "\n",
    "2-Independence: The residuals are independent. In particular, there is no correlation between consecutive residuals in time series data.\n",
    "\n",
    "3-Homoscedasticity: The residuals have constant variance at every level of the independent variable(s).\n",
    "\n",
    "4-Normality: The residuals of the model are normally distributed.\n",
    "\n",
    "There are several ways to check whether these assumptions hold in a given dataset. For example, to check for linearity, you can create a scatter plot of the independent variable(s) vs. the dependent variable and visually inspect whether there is a linear relationship 1. To check for independence, you can look at a residual time series plot, which is a plot of residuals vs. time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ded4fbd-1b17-4517-91f3-6ba5e4a08b85",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using\n",
    "a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2b7ecf-3186-4de7-9b32-79afeb58b2a8",
   "metadata": {},
   "source": [
    "In a simple linear regression model, the slope represents the average change in the dependent variable for every one-unit increase in the independent variable. The intercept represents the expected value of the dependent variable when the independent variable is equal to zero.\n",
    "\n",
    "For example, let’s say we have a linear regression model that predicts a person’s weight (in pounds) based on their height (in inches). The equation for this model might be: weight = 5 * height - 100.\n",
    "\n",
    "In this case, the slope is 5, which means that for every additional inch of height, a person’s weight is expected to increase by an average of 5 pounds. The intercept is -100, which means that if a person had a height of 0 inches (which is not possible in reality), their predicted weight would be -100 pounds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870e2318-2707-4d9f-8832-b7ee02b8e7b2",
   "metadata": {},
   "source": [
    "Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102abfa1-b102-42b6-b0e6-47aa9b8544e3",
   "metadata": {},
   "source": [
    "Gradient descent is an optimization algorithm commonly used to train machine learning models by minimizing errors between predicted and actual results. It works by iteratively adjusting the model’s parameters to find the values that minimize the cost function.\n",
    "\n",
    "The cost function measures the difference between the actual and predicted values at the current position. The goal of gradient descent is to minimize this cost function using iteration. To achieve this goal, it performs two steps iteratively: calculates the first-order derivative of the function to compute the gradient or slope of that function, and moves away from the direction of the gradient by a certain amount determined by the learning rate.\n",
    "\n",
    "The learning rate is a tuning parameter in the optimization process that helps determine the size of the steps taken towards the minimum. A high learning rate results in larger steps but risks overshooting the minimum, while a low learning rate has smaller step sizes but may take longer to reach the minimum ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe86daa2-d071-43af-8cb6-4397386c474e",
   "metadata": {},
   "source": [
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b33dbc-7b63-4cff-9a32-2236c6123e6a",
   "metadata": {},
   "source": [
    "Multiple linear regression is a statistical method used to model the relationship between a dependent variable and two or more independent variables. It is an extension of simple linear regression, which models the relationship between a dependent variable and a single independent variable.\n",
    "\n",
    "In multiple linear regression, the model takes the form of an equation that describes a hyperplane that best fits the data. The coefficients in the equation represent the change in the dependent variable for a one-unit change in the corresponding independent variable, while controlling for the other independent variables.\n",
    "\n",
    "The main difference between multiple linear regression and simple linear regression is the number of independent variables. In simple linear regression, there is only one independent variable, while in multiple linear regression there are two or more independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704271b7-ba39-4a52-821e-7a01d85986c0",
   "metadata": {},
   "source": [
    "Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\n",
    "address this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d3c98e-b8be-4b4f-944b-98ae3f9215d2",
   "metadata": {},
   "source": [
    "Multicollinearity occurs when two or more independent variables in a multiple regression model are highly correlated with one another. This can cause problems when interpreting the model because it becomes difficult to isolate the relationship between each independent variable and the dependent variable.\n",
    "\n",
    "There are several ways to detect multicollinearity in a dataset. One way is to calculate the variance inflation factor (VIF) for each independent variable. A VIF value greater than 5 or 10 indicates that the variable is highly correlated with other independent variables in the model. Another way to detect multicollinearity is to create a correlation matrix or heat map to visually inspect the correlations between independent variables.\n",
    "\n",
    "If multicollinearity is detected, there are several ways to address the issue. One way is to remove one of the correlated independent variables from the model. Another way is to combine the correlated independent variables into a single variable, such as by taking the average or principal component ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa4bfca-a353-42bf-9506-b906597062ad",
   "metadata": {},
   "source": [
    "Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344fa76e-d311-41a6-a608-eb7c3dcc2426",
   "metadata": {},
   "source": [
    "Polynomial regression is a form of regression analysis in which the relationship between the independent variable x and the dependent variable y is modeled as an nth degree polynomial in x. It is used to model non-linear relationships between the independent and dependent variables.\n",
    "\n",
    "In contrast, linear regression models the relationship between the independent and dependent variables as a straight line. While polynomial regression can fit more complex, non-linear relationships, it can also be more prone to overfitting if the degree of the polynomial is too high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f5f804-8f99-4458-ac84-77295e30d2a2",
   "metadata": {},
   "source": [
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b13e066-a008-495a-bbe1-f86f5a91819b",
   "metadata": {},
   "source": [
    "Polynomial regression has several advantages over linear regression. One advantage is that it can model non-linear relationships between the independent and dependent variables. This allows it to fit more complex data patterns and provide a better fit to the data.\n",
    "\n",
    "However, polynomial regression also has some disadvantages. One disadvantage is that it can be more prone to overfitting if the degree of the polynomial is too high. Overfitting occurs when the model fits the data too well, including the noise and random fluctuations in the data. This can result in a model that has poor predictive performance on new data.\n",
    "\n",
    "Polynomial regression is preferred over linear regression in situations where there is a non-linear relationship between the independent and dependent variables. In such cases, a linear regression model may not provide a good fit to the data, while a polynomial regression model can provide a better fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be818d5e-71d1-4853-a62d-6ba546949c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
