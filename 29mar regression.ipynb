{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ad0fc7e-a63e-42aa-8aad-72a7c44e67c5",
   "metadata": {},
   "source": [
    "Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7790584-ff57-4968-9f6f-b9ec9aebdfab",
   "metadata": {},
   "source": [
    "Lasso Regression is a regression analysis method that performs both variable selection and regularization. Lasso regression uses soft thresholding. Lasso regression selects only a subset of the provided covariates for use in the final model.\n",
    "\n",
    "Lasso regression differs from ridge regression in a way that it uses absolute values in the penalty function, instead of squares. This leads to penalizing (or equivalently constraining the sum of the absolute values of the estimates) values which causes some of the parameter estimates to turn out exactly zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1500f2-51c2-4bc4-aad4-03884cdaf14c",
   "metadata": {},
   "source": [
    "Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884d2110-49fa-48c7-81e1-d5fc1d618b77",
   "metadata": {},
   "source": [
    "The main advantage of using Lasso Regression in feature selection is that it provides a principled way to reduce the number of features in a model. By adding the L1 regularization term, Lasso regression can shrink the coefficients towards zero, and when λ is sufficiently large, some coefficients are driven to exactly zero. This property of Lasso makes it useful for feature selection, as the variables with zero coefficients are effectively removed from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f988860c-8c1c-46e8-912c-a99796e62808",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b380a11c-fbc3-4b38-b96c-bab175ff4cd3",
   "metadata": {},
   "source": [
    "The coefficients of a Lasso Regression model are interpreted in the same way as other linear regression models. The coefficient value signifies how much the mean of the dependent variable changes given a one-unit shift in the independent variable while holding other variables in the model constant. However, Lasso regression performs L1 regularization, which adds a penalty equal to the absolute value of the magnitude of coefficients. This type of regularization can result in sparse models with few coefficients; Some coefficients can become zero and eliminated from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf848f2-a79b-43db-a5fd-4cac415cbdbb",
   "metadata": {},
   "source": [
    "Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the\n",
    "model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b61540-d9ab-46ca-bb5d-e039ead74842",
   "metadata": {},
   "source": [
    "In Lasso Regression, the main tuning parameter is λ (lambda), which controls the strength of the L1 penalty term. It is basically the amount of shrinkage, where data values are shrunk towards a central point, like the mean. The value of λ can be adjusted to control the model’s performance. When λ = 0, the objective is equivalent to ordinary least squares, solved by the LinearRegression object. As λ increases, more coefficients are driven to zero, effectively removing them from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b3670c-6bd2-4d41-a752-4e4c1441093e",
   "metadata": {},
   "source": [
    "Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b030b3-1bd4-4083-ad70-f87b5786ec5c",
   "metadata": {},
   "source": [
    "Yes, Lasso Regression can be used for non-linear regression problems. One way to do this is by constructing non-linear regression models with basis functions, using Lasso regularization. Regularization with a Lasso penalty is advantageous in that it estimates some coefficients in linear regression models to be exactly zero. This can be used to effectively select the number of basis functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4aff45-d4d4-464f-9c59-6d16b904d663",
   "metadata": {},
   "source": [
    "Q6. What is the difference between Ridge Regression and Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c33e706-c566-4370-bd41-151f81f668b9",
   "metadata": {},
   "source": [
    "Ridge Regression and Lasso Regression are both methods of regularization used to prevent overfitting in regression models. The main difference between the two methods lies in the type of penalty applied to the coefficients.\n",
    "\n",
    "Ridge Regression applies an L2 penalty to the coefficients, which shrinks all coefficients towards zero but does not set any of them exactly to zero. This means that all variables remain in the model, but their influence is reduced.\n",
    "\n",
    "Lasso Regression, on the other hand, applies an L1 penalty to the coefficients. This type of penalty can set some coefficients exactly to zero, effectively removing them from the model. This makes Lasso Regression useful for feature selection.\n",
    "\n",
    "In summary, Ridge Regression reduces the magnitude of all coefficients while keeping all variables in the model, while Lasso Regression can set some coefficients to zero and remove some variables from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1215c895-d49a-47a8-8ddd-6dfef488ab02",
   "metadata": {},
   "source": [
    "Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e1bbe3-6797-40a6-bcc7-29320f0f3f12",
   "metadata": {},
   "source": [
    "Yes, Lasso Regression can handle multicollinearity in the input features. Multicollinearity occurs when two or more input features are highly correlated with each other. This can cause problems in regression models because it becomes difficult to determine the individual effect of each feature on the output variable.\n",
    "\n",
    "Lasso Regression addresses this issue by applying an L1 penalty to the coefficients. This type of penalty can set some coefficients exactly to zero, effectively removing them from the model. In the presence of multicollinearity, Lasso Regression will tend to keep only one of the correlated features and set the coefficients of the others to zero. This helps to reduce the impact of multicollinearity on the model.\n",
    "\n",
    "In summary, Lasso Regression can handle multicollinearity by removing some of the correlated features from the model through the use of an L1 penalty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbef90bd-ebda-40bb-b346-fa9e5df5b4d8",
   "metadata": {},
   "source": [
    "Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa39d26-2140-4008-af0b-a4b460a1d753",
   "metadata": {},
   "source": [
    "In Lasso Regression, the optimal value of the regularization parameter lambda can be chosen using cross-validation. Cross-validation is a technique used to assess how well a model will generalize to new data. It involves dividing the data into several subsets and training the model on some of these subsets while evaluating its performance on the remaining subsets.\n",
    "\n",
    "In the context of Lasso Regression, cross-validation can be used to choose the optimal value of lambda by evaluating the model’s performance for different values of lambda and selecting the value that gives the best performance. This can be done using a grid search, where a range of values for lambda is specified and the model is evaluated for each value in the range.\n",
    "\n",
    "In summary, the optimal value of lambda in Lasso Regression can be chosen using cross-validation and grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6183a800-a861-4445-a411-04c071e077cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
