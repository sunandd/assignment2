{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "417bb4c9-3ccc-4ad4-832e-a6f48acce4dc",
   "metadata": {},
   "source": [
    "Q1. What is Ridge Regression, and how does it differ from ordinary least squares regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023e9511-e245-4c47-ab91-d499fc68b904",
   "metadata": {},
   "source": [
    "Ridge Regression is a technique used when the data suffers from multicollinearity (independent variables are highly correlated). In multicollinearity, even though the least squares estimates (OLS) are unbiased, their variances are large which deviates the observed value far from the true value. Ridge regression tries to find the coefficients that minimize the mean squared error and wants the magnitude of coefficients to be as small as possible.\n",
    "\n",
    "Ridge regression differs from ordinary least squares regression in several ways. Ridge regression produces a lower test mean squared error compared to least squares regression when multicollinearity is present. Ridge regression uses a ridge estimator to estimate the coefficients, which is biased but has lower variance than the OLS estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504a1405-cb9b-4c89-8930-3ec984569094",
   "metadata": {},
   "source": [
    "Q2. What are the assumptions of Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2482aa-cd26-4f7e-a024-b65e1756aae0",
   "metadata": {},
   "source": [
    "The assumptions of ridge regression are the same as that of linear regression: linearity, constant variance, and independence. However, as ridge regression does not provide confidence limits, the distribution of errors to be normal need not be assumed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e75b2b-1c45-4be2-8844-534f51560e10",
   "metadata": {},
   "source": [
    "Q3. How do you select the value of the tuning parameter (lambda) in Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7014d9c-1ee0-45c3-b4ce-5170a91cc491",
   "metadata": {},
   "source": [
    "In ridge regression, the tuning parameter lambda is chosen by cross-validation. The idea is to make the fit small by making the residual sum of squares small plus adding a shrinkage penalty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727f99c5-6984-47a9-bc65-345a64d38a77",
   "metadata": {},
   "source": [
    "Q4. Can Ridge Regression be used for feature selection? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d1fb78-aefb-42b7-8f64-37e3baeb3353",
   "metadata": {},
   "source": [
    "Ridge regression can be used for feature selection while fitting the model. However, ridge regression does not attempt to select features at all, it instead uses a penalty applied to the sum of the squares of all regression coefficients. Ridge regression can be seen as doing the feature ‘selection’ in a nuanced way by reducing the size of the coefficients instead of setting them equal to zero. However, this method is a bit crude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8870d3f-6200-42d0-aace-5ae8ec886444",
   "metadata": {},
   "source": [
    "Q5. How does the Ridge Regression model perform in the presence of multicollinearity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea6d73f-8ed4-437e-a166-a34d334d4a55",
   "metadata": {},
   "source": [
    "Ridge regression is a method used for the analysis of multicollinearity in multiple regression data. It is most suitable when a data set contains a higher number of predictor variables than the number of observations. Ridge regression reduces the standard errors by introducing a degree of bias to the regression estimates, making the estimates more reliable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089f33a7-782a-47dc-9195-e0edc87fc5d7",
   "metadata": {},
   "source": [
    "Q6. Can Ridge Regression handle both categorical and continuous independent variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1244137f-358f-4196-b5c2-2411df9f36be",
   "metadata": {},
   "source": [
    "Ridge regression is used for regression purposes only and requires the dependent variable to be continuous. However, categorical independent variables can be included in a ridge regression model by encoding them as dummy variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7d7d9b-9a57-47fe-a9e8-4212a618c680",
   "metadata": {},
   "source": [
    "Q7. How do you interpret the coefficients of Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e764e80-0562-42ed-b6ce-c122755294bd",
   "metadata": {},
   "source": [
    "In ridge regression, the coefficients are defined as a response vector y ∈ Rn and a predictor matrix X ∈ Rn×p. The coefficient value signifies how much the mean of the dependent variable changes given a one-unit shift in the independent variable while holding other variables in the model constant. The turning factor λ controls the strength of the penalty term. If λ = 0, the objective becomes similar to simple linear regression, and we get the same coefficients as simple linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd6e229-9d09-4e90-a5b4-77235efab71e",
   "metadata": {},
   "source": [
    "Q8. Can Ridge Regression be used for time-series data analysis? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7b2668-448b-4112-91d1-755b5722bb61",
   "metadata": {},
   "source": [
    "Yes, Ridge Regression can be used for time-series data analysis. In time series regression, the dependent variable is a time series, and the independent variables can be other time series or non-time series variables. Time series regression helps you understand the relationship between variables over time and forecast future values of the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a446229b-cc90-4981-bd4e-bfc4a6e49ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
